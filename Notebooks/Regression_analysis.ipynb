{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6405ac",
   "metadata": {},
   "source": [
    "# <center><font color='#F1B03D'>**Revenue Intelligence Enhancement for BrokerChooser - Inferential Regression Analysis**</font></center>\n",
    "### <center><font color='#F1B03D'>Central European University, 2024-2025</font></center>\n",
    "### <center><font color='#F1B03D'>CEU Capstone Project</font></center>\n",
    "\n",
    "### <left><font color='#F1B03D'>Author: Péter Bence Török (torokpe@gmail.com)</font></left>\n",
    "### <left><font color='#F1B03D'>BrokerChooser Contact Person: Zoltán Molnár (zoltan.molnar@brokerchooser.com)</font></left>\n",
    "\n",
    "---\n",
    "<p style=\"font-size:22px;\"> This notebook uses a pre-processed dataset to perform an inferential regression analysis using a logistic (logit) model. The analysis estimates the relationship between session-level variables and the likelihood of revenue generation. The output includes a summary table displaying the coefficients for each variable, along with their standard errors, confidence intervals, and indicators of statistical significance. This provides a clear overview of which features are most strongly associated with the target outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f94a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sampled dataset from a CSV file\n",
    "df = pd.read_csv('path/to/file_location/data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies for categorical variables\n",
    "df = pd.get_dummies(df, columns=['country', 'device', 'traffic_name', 'traffic_medium','browser','op_system', 'day_of_month', 'start_event_hour', 'day_of_week'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping selected reference categories\n",
    "cols_to_drop = ['country_other', 'device_other', 'traffic_name_other',\n",
    "                'traffic_medium_other', 'browser_other', 'op_system_other', 'day_of_month_1','start_event_hour_0', 'day_of_week_0']\n",
    "\n",
    "df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the formula automatically\n",
    "all_vars = df.columns.difference(['generated_revenue'])  # exclude target\n",
    "formula = 'generated_revenue ~ ' + ' + '.join(all_vars)\n",
    "\n",
    "# Fit the model\n",
    "model = smf.logit(formula=formula, data=df)\n",
    "result = model.fit()\n",
    "\n",
    "# View summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# McFadden's pseudo-R²\n",
    "llf = result.llf           # Log-likelihood of the fitted model\n",
    "llnull = result.llnull     # Log-likelihood of the null model\n",
    "\n",
    "pseudo_r2 = 1 - (llf / llnull)\n",
    "print(f\"McFadden's R²: {pseudo_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3dffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting coefficient table\n",
    "summary_table = result.summary2().tables[1]\n",
    "\n",
    "# Adding significance stars\n",
    "def significance_stars(p):\n",
    "    if p < 0.001: return '***'\n",
    "    elif p < 0.01: return '**'\n",
    "    elif p < 0.05: return '*'\n",
    "    elif p < 0.1: return '.'\n",
    "    else: return ''\n",
    "\n",
    "summary_table['Significance'] = summary_table['P>|z|'].apply(significance_stars)\n",
    "\n",
    "# Renaming and selecting columns\n",
    "export_df = summary_table.reset_index()[['index', 'Coef.', 'Std.Err.', '[0.025', '0.975]', 'Significance']]\n",
    "export_df.columns = ['Variable', 'Coefficient', 'Std. Error', 'CI Lower', 'CI Upper', 'Significance']\n",
    "\n",
    "# Export to Excel\n",
    "export_df.to_excel(\"path/to/file_location/logit_summary_export.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
